{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pRF2SBrrEwQX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da25c7ed-7feb-40c5-ab35-7691c315e4b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install feature_engine\n",
        "!pip install tensorflow_addons"
      ],
      "metadata": {
        "id": "8dokntAi8udB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8964a55d-f22d-4a76-c484-091b9189359f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting feature_engine\n",
            "  Downloading feature_engine-1.5.2-py2.py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.0/290.0 KB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.0.3 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (1.3.5)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (1.7.3)\n",
            "Requirement already satisfied: statsmodels>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (0.12.2)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (1.0.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.3->feature_engine) (2022.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.3->feature_engine) (2.8.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->feature_engine) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->feature_engine) (1.2.0)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.8/dist-packages (from statsmodels>=0.11.1->feature_engine) (0.5.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from patsy>=0.5->statsmodels>=0.11.1->feature_engine) (1.15.0)\n",
            "Installing collected packages: feature_engine\n",
            "Successfully installed feature_engine-1.5.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow_addons) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow_addons) (3.0.9)\n",
            "Installing collected packages: tensorflow_addons\n",
            "Successfully installed tensorflow_addons-0.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import joblib # saving sklearn modules\n",
        "from sklearn.impute import KNNImputer # completing missing values using k-Nearest Neighbors\n",
        "from sklearn.metrics import accuracy_score # prediction scores\n",
        "from feature_engine.encoding import WoEEncoder # encode only categorical variables (type ‘object’)\n",
        "from sklearn.linear_model import LogisticRegression, HuberRegressor\n",
        "\n",
        "from tensorflow.keras import Sequential  \n",
        "from tensorflow.keras.layers import BatchNormalization, Dropout, Dense\n",
        "import tensorflow as tf\n",
        "from tensorflow_addons.optimizers import AdamW\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
      ],
      "metadata": {
        "id": "Ex1wyB8P8v-J"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Train = pd.read_csv('/content/drive/MyDrive/大三上作業/ML_final/train.csv')\n",
        "Test = pd.read_csv('/content/drive/MyDrive/大三上作業/ML_final/test.csv')\n",
        "submission = pd.read_csv('/content/drive/MyDrive/大三上作業/ML_final/sample_submission.csv')"
      ],
      "metadata": {
        "id": "dTuA2bLZDA7L"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.concat([Train, Test])\n",
        "# create lists that will be used\n",
        "codes = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I']\n",
        "drops = ['id', 'product_code', 'loading', 'attribute_0', 'attribute_1', 'attribute_2', 'attribute_3', 'loading', 'missing3', 'missing5']\n",
        "featureM = [f for f in data.columns if f.startswith('measurement') or f=='loading']\n",
        "features = ['loading', 'attribute_0', 'measurement_17', 'measurement_0','measurement_1', 'measurement_2', 'attr23', 'missing3', 'missing5']\n",
        "\n",
        "# create a dict for measurements 3-17 because they contain value lost (*reference)\n",
        "measurements = {}\n",
        "# set up measurement 17 manually\n",
        "measurements['measurement_17'] = {\n",
        "        'A': ['measurement_5','measurement_6','measurement_8','measurement_7'],\n",
        "        'B': ['measurement_4','measurement_5','measurement_7','measurement_9'],\n",
        "        'C': ['measurement_5','measurement_7','measurement_8','measurement_9'],\n",
        "        'D': ['measurement_5','measurement_6','measurement_7','measurement_8'],\n",
        "        'E': ['measurement_4','measurement_5','measurement_6','measurement_8'],\n",
        "        'F': ['measurement_4','measurement_5','measurement_6','measurement_7'],\n",
        "        'G': ['measurement_4','measurement_6','measurement_8','measurement_9'],\n",
        "        'H': ['measurement_4','measurement_5','measurement_7','measurement_8','measurement_9'],\n",
        "        'I': ['measurement_3','measurement_7','measurement_8','measurement_9']\n",
        "    }\n",
        "\n",
        "# when measurement_3 is missing, the failure rate is 0.160 (much lower than average)    \n",
        "data['missing3'] = data['measurement_3'].isna().astype(np.int8)\n",
        "# when measurement_5 is missing, the failure rate is 0.254 (much higher than average)\n",
        "data['missing5'] = data['measurement_5'].isna().astype(np.int8)\n",
        "# attribute_2 has two values (5 and 8) which occur only in the training data, and another value (7) occurs only in the test data, attribute_3 is similar.\n",
        "data['attr23'] = data['attribute_2'] * data['attribute_3']\n",
        "\n",
        "# get the correlation values of measurements 3-16\n",
        "colName = []\n",
        "value = []\n",
        "for i in range(3,17):\n",
        "    colName.append(f'measurement_{i}')\n",
        "    corr = np.absolute(data.drop(drops, axis=1).corr()[f'measurement_{i}']).sort_values(ascending=False)\n",
        "    value.append(np.sum(corr[1:4]))\n",
        "\n",
        "# take the measurements in order of sorted correlation\n",
        "measurementCorr = pd.DataFrame({'column name': colName, 'values': value})\n",
        "sortedMeasurement = measurementCorr.sort_values(by='values', ascending=False).reset_index(drop=True)\n",
        "for i in range(10): # only take the top 10\n",
        "    whichMeasurement = sortedMeasurement.iloc[i, 0]\n",
        "    best4 = {} # pick 4 measurements with best correlations for each product_code\n",
        "    for c in codes: \n",
        "        corr = np.absolute(data[data.product_code == c].drop(drops, axis=1).corr()[whichMeasurement]).sort_values(ascending=False)\n",
        "        best4[c] = corr[1:5].index.tolist()\n",
        "    measurements[whichMeasurement] = best4 # measurement_i | product_code : measurement_i1, measurement_i2, measurement_i3, measurement_i4\n",
        "\n",
        "# for each product_code\n",
        "for code in codes:\n",
        "    # fill the measurement columns with linear model\n",
        "    for measure in list(measurements.keys()):\n",
        "        dataM = data[data.product_code == code]\n",
        "        best4 = measurements[measure][code] # product_code : measurement_i1, measurement_i2, measurement_i3, measurement_i4\n",
        "        trainM = dataM[best4+[measure]].dropna(how='any') # 4 related + itself as target (all should not be null)\n",
        "        testM = dataM[(dataM[best4].isnull().sum(axis=1)==0) & (dataM[measure].isnull())] # 4 related (no null) + itself as target (null)\n",
        "        modelLinear = HuberRegressor(epsilon=1.75)\n",
        "        modelLinear.fit(trainM[best4], trainM[measure])\n",
        "        data.loc[(data.product_code==code)&(data[best4].isnull().sum(axis=1)==0)&(data[measure].isnull()), measure] = modelLinear.predict(testM[best4])\n",
        "    # fill the others N/A columns with KNN (k=3)\n",
        "    modelKnn = KNNImputer(n_neighbors=3)\n",
        "    data.loc[data.product_code==code, featureM] = modelKnn.fit_transform(data.loc[data.product_code==code, featureM])\n",
        "    \n",
        "# encode the data    \n",
        "train = data.iloc[:len(Train.index)]\n",
        "test = data.iloc[len(Train.index):]\n",
        "encode = WoEEncoder(variables=['attribute_0'])\n",
        "encode.fit(train, train['failure'])\n",
        "train = encode.transform(train)\n",
        "test = encode.transform(test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkJqv0IZDBkc",
        "outputId": "2cb85809-8850-43c6-da2e-826240d7a11f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(85)\n",
        "from keras.models import load_model\n",
        "Model = load_model('best.h5')\n",
        "predictions = Model.predict(test[features].values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0YEVtPwCzQv",
        "outputId": "7ff82ddf-000d-42a4-e181-cad255f68aca"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "650/650 [==============================] - 5s 7ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "submission['failure'] = predictions\n",
        "submission.to_csv('output.csv', index=False)\n",
        "files.download('output.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "eOZIeD64C4fz",
        "outputId": "933fec6a-b243-40ba-e0c7-80f29c9eea3e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2784b6bc-4317-4fa9-bac4-2501f79a588e\", \"output.csv\", 349147)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze >requirements.txt"
      ],
      "metadata": {
        "id": "atSDzxs8Gf4o"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}